{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "17bbd38e",
   "metadata": {},
   "source": [
    "### setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07577741",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "from itertools import combinations\n",
    "from pathlib import Path\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import numpy as np\n",
    "import probeinterface\n",
    "import spikeinterface as si\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from probeinterface import get_probe, Probe\n",
    "from probeinterface.plotting import plot_probe\n",
    "from spikeinterface import (\n",
    "    BinaryFolderRecording,\n",
    "    comparison,\n",
    "    concatenate_recordings,\n",
    "    exporters,\n",
    "    extractors,\n",
    "    postprocessing,\n",
    "    preprocessing,\n",
    "    sorters,\n",
    "    qualitymetrics,\n",
    "    widgets,\n",
    ")\n",
    "\n",
    "\n",
    "print(f\"SpikeInterface version: {si.__version__}\")\n",
    "\n",
    "warnings.simplefilter(\"ignore\")\n",
    "%matplotlib inline\n",
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a6b6da6",
   "metadata": {},
   "source": [
    "### load recording"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bc4ad10",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def prepare_recording(\n",
    "    subject_id: str = \"subject_1\",\n",
    "    trial_id: str = \"2020-08-22\",\n",
    "    take_slice: bool = False,\n",
    "    slice_size: int = 300,\n",
    "    verbose: bool = True,\n",
    ") -> BinaryFolderRecording:\n",
    "    \"\"\"loads the neural recording of the given trial, concatenates its segments\n",
    "    into one joint object, then exports and loads the it in a sorting-ready format\"\"\"\n",
    "    import_path = f\"data/raw/{subject_id}/{trial_id}/\"\n",
    "    segmented_recording = extractors.read_neuralynx(import_path, stream_id=\"0\")\n",
    "    joint_recording = concatenate_recordings(\n",
    "        list(\n",
    "            map(\n",
    "                segmented_recording.select_segments,\n",
    "                range(segmented_recording.get_num_segments()),\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "    fs = joint_recording.get_sampling_frequency()\n",
    "    if verbose:\n",
    "        nch = joint_recording.get_num_channels()\n",
    "        dur = joint_recording.get_total_duration()\n",
    "        print(\n",
    "            \"\\n\".join(\n",
    "                (\n",
    "                    \"Recording loaded\",\n",
    "                    f\"Sampling frequency: {fs} Hz\",\n",
    "                    f\"Number of channels: {nch}\",\n",
    "                    f\"Total duration: {dur:.2f} seconds\",\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "\n",
    "    recording_slice = (\n",
    "        joint_recording.frame_slice(\n",
    "            start_frame=0 * fs,\n",
    "            end_frame=slice_size * fs,\n",
    "        )\n",
    "        if take_slice\n",
    "        else joint_recording\n",
    "    )\n",
    "    export_path = import_path.replace(\"raw\", \"slices\" if take_slice else \"prepared\")\n",
    "    recording_saved = recording_slice.save(folder=export_path, verbose=False)\n",
    "    recording_loaded = si.load_extractor(export_path)\n",
    "    return recording_loaded\n",
    "\n",
    "\n",
    "recording = prepare_recording()\n",
    "# recording_slice = prepare_recording(take_slice=True, verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05c176d4",
   "metadata": {},
   "source": [
    "### visualize recording"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10e970b7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "raw_plot = widgets.plot_timeseries(recording, backend=\"ipywidgets\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8b9f8ac",
   "metadata": {},
   "source": [
    "### add fake probe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "924116ef",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def compute_min_dist(positions: np.ndarray) -> float:\n",
    "    \"\"\"computes the minimal distance between any two channels on the given probe\"\"\"\n",
    "    channel_pairs = combinations(positions, 2)\n",
    "    channel_distances = np.linalg.norm([p1 - p2 for p1, p2 in channel_pairs], axis=1)\n",
    "    return channel_distances.min()\n",
    "\n",
    "\n",
    "positions = np.random.uniform(low=0, high=100, size=(16, 2))\n",
    "while not compute_min_dist(positions) >= 10:\n",
    "    positions = np.random.uniform(low=0, high=100, size=(16, 2))\n",
    "\n",
    "probe = Probe()\n",
    "probe.set_contacts(positions=positions, shapes=\"circle\", shape_params=dict(radius=5))\n",
    "probe.set_device_channel_indices(np.arange(recording.get_num_channels()))\n",
    "rec_w_probe = recording.set_probe(probe)\n",
    "\n",
    "%matplotlib inline\n",
    "plot_probe(probe)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1babd1d6",
   "metadata": {},
   "source": [
    "### run sorters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4a9d909",
   "metadata": {},
   "outputs": [],
   "source": [
    "docker_dict = dict(\n",
    "    # combinato=\"spikeinterface/combinato-base:latest\", # single channel\n",
    "    hdsort=\"spikeinterface/hdsort-compiled-base:latest\",\n",
    "    herdingspikes=\"spikeinterface/herdingspikes-base:latest\",\n",
    "    ironclust=\"spikeinterface/ironclust-compiled-base:latest\",\n",
    "    # kilosort=\"spikeinterface/kilosort-compiled-base:latest\", # requires GPU\n",
    "    # kilosort2=\"spikeinterface/kilosort2-compiled-base:latest\", # requires GPU\n",
    "    # kilosort2_5=\"spikeinterface/kilosort2_5-compiled-base:latest\", # requires GPU\n",
    "    # klusta=\"spikeinterface/klusta-base:latest\", # error in docker image\n",
    "    mountainsort4=\"spikeinterface/mountainsort4-base:latest\",\n",
    "    # pykilosort=\"spikeinterface/pykilosort-base:latest\", # requires GPU\n",
    "    spykingcircus=\"spikeinterface/spyking-circus-base:latest\",\n",
    "    tridesclous=\"spikeinterface/tridesclous-base:latest\",\n",
    "    waveclus=\"spikeinterface/waveclus-compiled-base:latest\",\n",
    "    # yass=\"spikeinterface/yass-base:latest\", # requires GPU\n",
    ")\n",
    "\n",
    "sorting_dict = dict()\n",
    "\n",
    "param_dict = {\n",
    "    sorter: sorters.get_default_sorter_params(sorter)\n",
    "    for sorter in sorters.available_sorters()\n",
    "}\n",
    "\n",
    "for sorter, image in tqdm(docker_dict.items()):\n",
    "    try:\n",
    "        filter_kwarg = dict(filter=False) if \"filter\" in param_dict[sorter] else dict()\n",
    "        sorting_dict[sorter] = sorters.run_sorter(\n",
    "            sorter,\n",
    "            rec_w_probe,\n",
    "            docker_image=image,\n",
    "            output_folder=f\"data/sorted/{sorter}\",\n",
    "            **filter_kwarg,\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(f\"Sorting with {sorter} failed due to the following exception: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c31318ef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "research",
   "language": "python",
   "name": "research"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
